{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5241014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9888360",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f3abec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc0f2d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a0a581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf23dde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt #to view graph in colab itself\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d5f26bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15750 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train=train_datagen.flow_from_directory(r'C:\\project\\conversation engine for deaf and dumb\\Dataset\\training_set',target_size=(64,64),batch_size=200,\n",
    "                                          class_mode='categorical',color_mode=\"grayscale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f21c7c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2250 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "x_test=test_datagen.flow_from_directory(r'C:\\project\\conversation engine for deaf and dumb\\Dataset\\test_set',target_size=(64,64),batch_size=200,\n",
    "                                          class_mode='categorical',color_mode=\"grayscale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8297280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da0559bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Convolution2D(32,(3,3),input_shape=(64,64,1),activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4a11955",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad850e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7331b699",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=512,activation='relu'))\n",
    "model.add(Dense(units=261,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3efb979",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=9,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "110c86bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2215cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91936\\AppData\\Local\\Temp\\ipykernel_7380\\234118701.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(x_train,steps_per_epoch=len(x_train),epochs=10,validation_data=x_test,validation_steps=len(x_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "79/79 [==============================] - 113s 1s/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.3487 - val_accuracy: 0.9738\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 112s 1s/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.3201 - val_accuracy: 0.9764\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 111s 1s/step - loss: 5.2562e-04 - accuracy: 1.0000 - val_loss: 0.3692 - val_accuracy: 0.9773\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 112s 1s/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.3651 - val_accuracy: 0.9769\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 113s 1s/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.3716 - val_accuracy: 0.9782\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 112s 1s/step - loss: 2.4746e-04 - accuracy: 1.0000 - val_loss: 0.3717 - val_accuracy: 0.9782\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 113s 1s/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.3136 - val_accuracy: 0.9791\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 112s 1s/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.4168 - val_accuracy: 0.9778\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 113s 1s/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.3165 - val_accuracy: 0.9791\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 115s 1s/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.3499 - val_accuracy: 0.9782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a8354e1be0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(x_train,steps_per_epoch=len(x_train),epochs=10,validation_data=x_test,validation_steps=len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd619c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('t21model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "661ecf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f590fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model('t21model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f48678a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=500x400>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=image.load_img(r'C:\\project\\conversation engine for deaf and dumb\\Dataset\\test_set\\A\\4.png',target_size=(400,500))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1ddffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "def detect(frame):\n",
    "    img=image.img_to_array(frame)\n",
    "    img = resize(img,(64,64,1))\n",
    "    img = np.expand_dims(img,axis=0)\n",
    "    pred=np.argmax(model.predict(img))\n",
    "    op=['A','B','C','D','E','F','G','H','I']\n",
    "    print(\"THE PREDICTED LETTER IS \",op[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a1bccc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 315ms/step\n",
      "THE PREDICTED LETTER IS  A\n"
     ]
    }
   ],
   "source": [
    "img=image.load_img(r\"C:\\project\\conversation engine for deaf and dumb\\Dataset\\test_set\\A\\4.png\")\n",
    "detect(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d16ae22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 111ms/step\n",
      "THE PREDICTED LETTER IS  G\n"
     ]
    }
   ],
   "source": [
    "img=image.load_img(r\"C:\\project\\conversation engine for deaf and dumb\\Dataset\\test_set\\G\\9.png\")\n",
    "detect(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "90094193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step\n",
      "THE PREDICTED LETTER IS  I\n"
     ]
    }
   ],
   "source": [
    "img=image.load_img(r\"C:\\project\\conversation engine for deaf and dumb\\Dataset\\test_set\\I\\26.png\")\n",
    "detect(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fcd048ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 80ms/step\n",
      "THE PREDICTED LETTER IS  C\n"
     ]
    }
   ],
   "source": [
    "img=image.load_img(r\"C:\\project\\conversation engine for deaf and dumb\\Dataset\\test_set\\C\\55.png\")\n",
    "detect(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07aae9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
